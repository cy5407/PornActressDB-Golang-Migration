# Research Report: SQLite è½‰æ›ç‚º JSON è³‡æ–™åº«å„²å­˜

**Feature**: 001-sqlite-to-json-conversion  
**Date**: 2025-10-16  
**Status**: Complete

---

## ç ”ç©¶ç™¼ç¾ç¸½çµ

æœ¬å ±å‘Šè¨˜éŒ„äº† SQLite â†’ JSON è½‰æ›çš„æ ¸å¿ƒæ±ºç­–å’ŒæŠ€è¡“è©•ä¼°ã€‚æ‰€æœ‰é—œéµæ­§ç¾©å·²è§£æ±ºï¼Œå»ºè­°é€²å…¥å¯¦æ–½éšæ®µã€‚

---

## R1: JSON å„²å­˜æ¶æ§‹è©•ä¼°

### æ±ºç­–
âœ… **é¸æ“‡æ–¹æ¡ˆ**: å–®ä¸€ JSON æª”æ¡ˆ + è¨˜æ†¶é«”å¿«å–

### åŸºæœ¬åŸç†
1. **ç°¡åŒ–å¯¦ä½œ**: ç„¡éœ€é¡å¤–è³‡æ–™åº«ç³»çµ±ï¼Œç´” Python æª”æ¡ˆæ“ä½œ
2. **ç‰ˆæœ¬æ§åˆ¶å‹å–„**: å¯ç›´æ¥æ”¾å…¥ Git (é©åˆå°è‡³ä¸­å‹è³‡æ–™é›†)
3. **é›¶ä¾è³´**: ä½¿ç”¨ Python å…§å»º `json` æ¨¡çµ„
4. **æ˜“æ–¼å‚™ä»½**: ç°¡å–®çš„æª”æ¡ˆç´šå‚™ä»½ç­–ç•¥

### æ›¿ä»£æ–¹æ¡ˆè©•ä¼°

| æ–¹æ¡ˆ | å„ªé» | ç¼ºé» | æ±ºç­– |
|-----|------|------|------|
| **å–®æª” JSON** | ç°¡å–®ã€Git å‹å–„ã€ç„¡ä¾è³´ | æ•ˆèƒ½å–æ±ºæ–¼è³‡æ–™é‡ | âœ… **é¸ä¸­** |
| å¤šæª”åˆ†ç‰‡ JSON | å¤§è³‡æ–™é›†å‹å–„ | è¤‡é›œæŸ¥è©¢å’Œèšåˆå›°é›£ | âŒ éåº¦è¨­è¨ˆ |
| DuckDB | æ•ˆèƒ½å„ªæ–¼ SQLite | ä»éœ€é·ç§»ï¼Œå¢åŠ ä¾è³´ | âŒ ä¸å¿…è¦ |
| MongoDB/CouchDB | å¤©ç„¶ JSON æ”¯æ´ | æ“ä½œè¤‡é›œåº¦é«˜ï¼Œè¶…å‡ºéœ€æ±‚ | âŒ éåº¦å·¥ç¨‹åŒ– |

### å¯¦æ–½ç´°ç¯€

```python
# æª”æ¡ˆçµæ§‹
data/json_db/
â”œâ”€â”€ actress_data.json           # ä¸»è³‡æ–™
â”œâ”€â”€ statistics_cache.json       # å¿«å–çµ±è¨ˆ
â”œâ”€â”€ backup/                     # å‚™ä»½ç›®éŒ„
â”‚   â”œâ”€â”€ actress_data.*.backup
â”‚   â””â”€â”€ BACKUP_MANIFEST.json
â””â”€â”€ .datalock                   # ä¸¦è¡Œæ§åˆ¶æ¨™è¨˜

# è¨˜æ†¶é«”å¿«å–ç­–ç•¥
- é¦–æ¬¡è¼‰å…¥æ™‚å¿«å–æ•´å€‹ JSON åˆ°è¨˜æ†¶é«”
- ä¿®æ”¹æ“ä½œå¾Œæ›´æ–°å¿«å–
- å®šæœŸåŒæ­¥å›ç£ç¢Ÿ (æ¯ 100 æ“ä½œæˆ–æ¯ 5 åˆ†é˜)
```

### æ•ˆèƒ½é æœŸ

| è³‡æ–™é‡ | æª”æ¡ˆå¤§å° | è¼‰å…¥æ™‚é–“ | æŸ¥è©¢å»¶é² | å¯«å…¥æ™‚é–“ |
|------|--------|--------|--------|--------|
| 150 ç­† | ~200KB | <10ms | 1-5ms | <100ms |
| 1,000 ç­† | ~1.5MB | 20-30ms | 5-20ms | 100-200ms |
| 10,000 ç­† | ~15MB | 100-200ms | 50-100ms | 500-1000ms |

**çµè«–**: é‡å° 150-10,000 ç­†è¨˜éŒ„ç¯„åœï¼Œæ•ˆèƒ½æ˜¯å¯æ¥å—çš„ã€‚

---

## R2: ä¸¦è¡Œæ§åˆ¶æ©Ÿåˆ¶

### æ±ºç­–
âœ… **é¸æ“‡æ–¹æ¡ˆ**: `filelock` å¥—ä»¶ + è®€å¯«é–

### åŸºæœ¬åŸç†
1. **è·¨å¹³å°æ”¯æ´**: Windowsã€Linuxã€macOS
2. **ç°¡å–® API**: æ˜“æ–¼æ•´åˆç¾æœ‰ç¨‹å¼ç¢¼
3. **æª”æ¡ˆç´šåˆ¥**: æ”¯æ´é€²ç¨‹ç´šåˆ¥ä¸¦è¡Œæ§åˆ¶
4. **æˆç†Ÿç©©å®š**: å»£æ³›ä½¿ç”¨çš„é–‹æºå°ˆæ¡ˆ

### å‚™é¸æ–¹æ¡ˆè©•ä¼°

| æ–¹æ¡ˆ | åŸç† | å„ªé» | ç¼ºé» | æ±ºç­– |
|-----|------|------|------|------|
| **filelock** | æ–‡ä»¶é–å®š | è·¨å¹³å°ã€ç°¡å–® | å–®æ©Ÿé™åˆ¶ | âœ… **é¸ä¸­** |
| fcntl (Unix) | POSIX é– | é«˜æ•ˆã€åŸç”Ÿ | ä¸æ”¯æ´ Windows | âŒ ä¸è·¨å¹³å° |
| threading.Lock | è¨˜æ†¶é«”é– | å¿«é€Ÿã€ç°¡å–® | åƒ…é™å–®é€²ç¨‹ | âŒ ä¸æ”¯æ´å¤šé€²ç¨‹ |
| Redis Lock | åˆ†æ•£å¼ | æ”¯æ´åˆ†ä½ˆå¼ | é¡å¤–ä¾è³´ã€è¤‡é›œ | âŒ éåº¦è¨­è¨ˆ |

### å¯¦æ–½æ–¹æ¡ˆ

```python
# è®€æ“ä½œ (å…±äº«é– - å¤šé€²ç¨‹å¯ä¸¦è¡Œ)
with filelock.FileLock("data/.read.lock", timeout=5):
    data = json.load(open("data/actress_data.json"))
    # åŸ·è¡Œåªè®€æ“ä½œ
    result = process_data(data)

# å¯«æ“ä½œ (ç¨ä½”é– - åºåˆ—åŒ–)
with filelock.FileLock("data/.write.lock", timeout=10):
    # è®€å–ç•¶å‰è³‡æ–™
    data = json.load(open("data/actress_data.json"))
    # ä¿®æ”¹è³‡æ–™
    data['videos'].append(new_video)
    # åŸå­å¯«å…¥
    with open("data/actress_data.json", "w") as f:
        json.dump(data, f)
```

### ä¸¦è¡Œå®‰å…¨æ€§é©—è­‰

```python
# æ¸¬è©¦å ´æ™¯: 5 é€²ç¨‹åŒæ™‚è®€å¯«
def test_concurrent_access():
    threads = []
    
    # 3 å€‹è®€é€²ç¨‹
    for i in range(3):
        t = threading.Thread(target=read_operation)
        threads.append(t)
    
    # 2 å€‹å¯«é€²ç¨‹  
    for i in range(2):
        t = threading.Thread(target=write_operation)
        threads.append(t)
    
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    
    # é©—è­‰è³‡æ–™ä¸€è‡´æ€§
    assert validate_data_integrity()
```

**é æœŸçµæœ**: âœ… ç„¡è³‡æ–™æå£æˆ–éºå¤±

---

## R3: è³‡æ–™é©—è­‰å’Œæ¢å¾©ç­–ç•¥

### æ±ºç­–
âœ… **é¸æ“‡æ–¹æ¡ˆ**: å¤šå±¤é©—è­‰ + è‡ªå‹•å‚™ä»½ + é€²åº¦è¨˜éŒ„

### é©—è­‰å±¤æ¬¡

#### å±¤æ¬¡ 1: æ ¼å¼é©—è­‰
```python
# ç¢ºä¿ JSON èªæ³•æ­£ç¢º
try:
    json.loads(file_content)
except json.JSONDecodeError:
    logger.error("JSON æ ¼å¼éŒ¯èª¤")
    restore_from_backup()
```

#### å±¤æ¬¡ 2: çµæ§‹é©—è­‰
```python
# ç¢ºä¿å¿…éœ€çš„é ‚å±¤éµå­˜åœ¨
required_keys = ['videos', 'actresses', 'video_actress_links']
for key in required_keys:
    assert key in data, f"Missing key: {key}"
```

#### å±¤æ¬¡ 3: å®Œæ•´æ€§é©—è­‰
```python
# SHA256 é›œæ¹Šæª¢æŸ¥
stored_hash = data['_metadata']['hash']
computed_hash = hashlib.sha256(
    json.dumps(data, sort_keys=True).encode()
).hexdigest()
if stored_hash != computed_hash:
    logger.warning("Data integrity check failed")
    restore_from_backup()
```

#### å±¤æ¬¡ 4: åƒç…§å®Œæ•´æ€§é©—è­‰
```python
# é©—è­‰å¤–éµç´„æŸ
video_ids = set(v['id'] for v in data['videos'])
for link in data['video_actress_links']:
    assert link['video_id'] in video_ids, "Invalid video reference"
```

### æ¢å¾©ç­–ç•¥

```python
def recover_from_corruption():
    """å¾æå£è‡ªå‹•æ¢å¾©"""
    
    # 1. å˜—è©¦ä¿®å¾©ç•¶å‰æª”æ¡ˆ
    if try_repair_json_file():
        return True
    
    # 2. å¾æœ€æ–°å‚™ä»½é‚„åŸ
    backups = get_backup_list()
    for backup in sorted(backups, reverse=True):
        if restore_from_backup(backup):
            logger.info(f"Restored from backup: {backup}")
            return True
    
    # 3. æœ€å¾Œæ‰‹æ®µ: ä½¿ç”¨ä¸Šæ¬¡æˆåŠŸçš„å¿«ç…§
    return restore_from_last_known_good()
```

### å‚™ä»½ç­–ç•¥

```
è‡ªå‹•å‚™ä»½æ™‚æ©Ÿ:
- é·ç§»å®Œæˆå¾Œ
- æ¯å¤©åˆå¤œ (å®šæ™‚å‚™ä»½)
- é‡å¤§æ“ä½œå‰ (æ–°å¢/åˆªé™¤å¤§é‡å½±ç‰‡)

å‚™ä»½ä¿ç•™æ”¿ç­–:
- æœ€è¿‘ 30 å¤©: ä¿ç•™æ‰€æœ‰å‚™ä»½
- 30 å¤©å‰: æ¯é€±ä¿ç•™ 1 å€‹
- é™åˆ¶: æœ€å¤š 50 å€‹å‚™ä»½æª”æ¡ˆ

å‚™ä»½é©—è­‰:
- æ¯å€‹å‚™ä»½å®Œæˆå¾Œé©—è­‰å®Œæ•´æ€§
- å®šæœŸæ¸¬è©¦å‚™ä»½é‚„åŸæµç¨‹ (é€±æœŸ: æ¯æœˆ)
```

---

## R4: æŸ¥è©¢ç­‰åƒ¹æ€§ - JOIN é‚è¼¯è½‰æ›

### æ±ºç­–
âœ… **é¸æ“‡æ–¹æ¡ˆ**: æ‰‹å‹• Python å¯¦ä½œ JOIN + é è¨ˆç®—å¿«å–

### åŸºæœ¬åŸç†

SQLite JOIN åœ¨ SQL å±¤åŸç”Ÿæ”¯æ´ï¼ŒJSON éœ€è¦åœ¨æ‡‰ç”¨å±¤æ‰‹å‹•å¯¦ä½œã€‚ç‚ºäº†æ•ˆèƒ½ï¼Œæ¡ç”¨é è¨ˆç®—çµ±è¨ˆå¿«å–ç­–ç•¥ã€‚

### è½‰æ›æ˜ å°„

#### æŸ¥è©¢ 1: å¥³å„ªçµ±è¨ˆ

**SQLite ç‰ˆæœ¬**:
```sql
SELECT 
  a.id, 
  a.name, 
  COUNT(DISTINCT v.id) as video_count,
  MAX(v.release_date) as latest_date
FROM actresses a
LEFT JOIN video_actress_links val ON a.id = val.actress_id
LEFT JOIN videos v ON val.video_id = v.id
GROUP BY a.id;
```

**JSON å¯¦ä½œ**:
```python
def get_actress_statistics():
    """è¨ˆç®—å¥³å„ªçµ±è¨ˆ (æ‰‹å‹• JOIN)"""
    actress_stats = {}
    
    for actress in self.data['actresses']:
        actress_id = actress['id']
        
        # å»ºç«‹å¥³å„ªè³‡è¨Š
        actress_stats[actress_id] = {
            'name': actress['name'],
            'video_count': 0,
            'videos': [],
            'latest_date': None
        }
        
        # æ‰¾åˆ°è©²å¥³å„ªçš„æ‰€æœ‰å½±ç‰‡ (JOIN)
        for link in self.data['video_actress_links']:
            if link['actress_id'] == actress_id:
                # æ‰¾åˆ°å½±ç‰‡è³‡è¨Š (JOIN)
                video = self._find_video(link['video_id'])
                if video:
                    actress_stats[actress_id]['videos'].append(video['id'])
                    actress_stats[actress_id]['video_count'] += 1
                    
                    # æ›´æ–°æœ€æ–°æ—¥æœŸ
                    if actress_stats[actress_id]['latest_date'] is None:
                        actress_stats[actress_id]['latest_date'] = video['release_date']
                    else:
                        if video['release_date'] > actress_stats[actress_id]['latest_date']:
                            actress_stats[actress_id]['latest_date'] = video['release_date']
    
    return actress_stats
```

#### æŸ¥è©¢ 2: äº¤å‰çµ±è¨ˆ (å¥³å„ª-ç‰‡å•†)

**SQLite ç‰ˆæœ¬**:
```sql
SELECT 
  a.id as actress_id,
  s.name as studio_name,
  COUNT(DISTINCT v.id) as video_count
FROM actresses a
JOIN video_actress_links val ON a.id = val.actress_id
JOIN videos v ON val.video_id = v.id
GROUP BY a.id, s.name;
```

**JSON å¯¦ä½œ**:
```python
def get_cross_statistics():
    """è¨ˆç®—å¥³å„ª-ç‰‡å•†äº¤å‰çµ±è¨ˆ"""
    cross_stats = {}  # key: (actress_id, studio)
    
    for link in self.data['video_actress_links']:
        video = self._find_video(link['video_id'])
        if not video:
            continue
        
        key = (link['actress_id'], video['studio'])
        if key not in cross_stats:
            cross_stats[key] = 0
        cross_stats[key] += 1
    
    # è½‰æ›ç‚ºé™£åˆ—æ ¼å¼
    result = []
    for (actress_id, studio), count in cross_stats.items():
        result.append({
            'actress': actress_id,
            'studio': studio,
            'video_count': count
        })
    
    return result
```

### æ•ˆèƒ½å„ªåŒ–

```python
# ç­–ç•¥ 1: é è¨ˆç®—çµ±è¨ˆå¿«å–
# é¿å…æ¯æ¬¡æŸ¥è©¢éƒ½é‡æ–°è¨ˆç®—
statistics_cache = {
    'actress_stats': {...},
    'studio_stats': {...},
    'cross_stats': [...],
    'last_updated': datetime.now()
}

# ç­–ç•¥ 2: å¢é‡æ›´æ–°
# æ–°å¢å½±ç‰‡æ™‚åªæ›´æ–°ç›¸é—œå¿«å–é …
def update_statistics_incremental(new_video):
    # åªæ›´æ–°å—æ–°å½±ç‰‡å½±éŸ¿çš„çµ±è¨ˆ
    pass

# ç­–ç•¥ 3: ç´¢å¼•å¿«é€ŸæŸ¥æ‰¾
# å»ºç«‹è¼”åŠ©ç´¢å¼•åŠ é€ŸæŸ¥è©¢
actress_video_index = {
    'actress_001': ['video_1', 'video_2', ...],
    'actress_002': ['video_3', ...]
}
```

### ç­‰åƒ¹æ€§é©—è­‰

```python
def verify_query_equivalence():
    """é©—è­‰ JSON æŸ¥è©¢çµæœèˆ‡ SQLite ç›¸åŒ"""
    
    # æŸ¥è©¢ SQLite çµæœ
    sqlite_actresses = query_sqlite(
        "SELECT id, name, COUNT(*) FROM actresses ..."
    )
    
    # æŸ¥è©¢ JSON çµæœ  
    json_actresses = json_db.get_actress_statistics()
    
    # å°æ¯”
    for actress_id, sqlite_stats in sqlite_actresses.items():
        json_stats = json_actresses[actress_id]
        assert sqlite_stats == json_stats, f"Mismatch for {actress_id}"
    
    return True  # ç­‰åƒ¹æ€§é©—è­‰é€šé
```

---

## R5: æŠ€è¡“ä¾è³´è©•ä¼°

### æ–°å¢ä¾è³´

```
filelock==3.13.0  # æª”æ¡ˆé–å®šï¼Œæ”¯æ´è·¨å¹³å°ä¸¦è¡Œå­˜å–
```

### ç§»é™¤ä¾è³´

é·ç§»å®Œæˆå¾Œç§»é™¤:
```
sqlite3  # å…§å»ºï¼Œä½†ç›¸é—œç¨‹å¼ç¢¼ç§»é™¤
```

### ä¾è³´ç›¸å®¹æ€§

| ä¾è³´ | ç‰ˆæœ¬ | Python ç›¸å®¹æ€§ | è¨±å¯è­‰ | ç‹€æ…‹ |
|-----|------|------------|-------|------|
| filelock | 3.13.0 | 3.8+ | Public Domain | âœ… ç©©å®š |
| json | å…§å»º | All | - | âœ… å…§å»º |
| hashlib | å…§å»º | All | - | âœ… å…§å»º |

---

## å¯¦æ–½å»ºè­°

### éšæ®µ 1: è¨­è¨ˆé©—è­‰ (1-2 å¤©)
1. å¯¦ä½œ JSONDBManager åŸå‹
2. åŸ·è¡Œä¸¦è¡Œæ¸¬è©¦
3. é©—è­‰æŸ¥è©¢ç­‰åƒ¹æ€§

### éšæ®µ 2: é·ç§»å·¥å…·é–‹ç™¼ (2-3 å¤©)
1. é–‹ç™¼ SQLite â†’ JSON è½‰æ›å·¥å…·
2. æ¸¬è©¦å¤§è³‡æ–™é›†é·ç§»
3. å»ºç«‹å‚™ä»½å’Œæ¢å¾©æ©Ÿåˆ¶

### éšæ®µ 3: é›†æˆæ¸¬è©¦ (2-3 å¤©)
1. æ¥­å‹™é‚è¼¯é©é…
2. UI å±¤æ›´æ–°
3. ç«¯åˆ°ç«¯æ¸¬è©¦

### éšæ®µ 4: éƒ¨ç½²æº–å‚™ (1 å¤©)
1. æ¸…ç†èˆŠç¨‹å¼ç¢¼
2. æ–‡ä»¶æ›´æ–°
3. æœ€çµ‚é©—è­‰

---

## é¢¨éšªè©•ä¼°å’Œç·©è§£

| é¢¨éšª | åš´é‡æ€§ | ç·©è§£ç­–ç•¥ |
|-----|------|--------|
| è³‡æ–™æå£ | ğŸ”´ é«˜ | å¤šå±¤é©—è­‰ + è‡ªå‹•å‚™ä»½ + é‚„åŸæ©Ÿåˆ¶ |
| ä¸¦è¡Œè¡çª | ğŸ”´ é«˜ | filelock ç¨ä½”é– + æ¸¬è©¦ |
| æ•ˆèƒ½ä¸‹é™ | ğŸŸ¡ ä¸­ | è¨˜æ†¶é«”å¿«å– + çµ±è¨ˆé è¨ˆç®— |
| é·ç§»å¤±æ•— | ğŸŸ¡ ä¸­ | ä¿ç•™ SQLite + åå‘é·ç§»å·¥å…· |
| ç›¸å®¹æ€§å•é¡Œ | ğŸŸ¢ ä½ | ç›¸åŒä»‹é¢è¨­è¨ˆ + å–®å…ƒæ¸¬è©¦ |

---

## çµè«–

æ‰€æœ‰é—œéµæ±ºç­–å‡åŸºæ–¼æŠ€è¡“è©•ä¼°å’Œæœ€ä½³å¯¦è¸ã€‚å»ºè­°æ–¹æ¡ˆï¼š

âœ… **JSON å„²å­˜**ï¼šå–®æª” + å¿«å–  
âœ… **ä¸¦è¡Œæ§åˆ¶**ï¼šfilelock  
âœ… **è³‡æ–™å®‰å…¨**ï¼šå¤šå±¤é©—è­‰ + è‡ªå‹•å‚™ä»½  
âœ… **æŸ¥è©¢é‚è¼¯**ï¼šæ‰‹å‹• JOIN + é è¨ˆç®—å¿«å–  

**æ•´é«”è©•ä¼°**: âœ… å¯è¡Œæ€§é«˜ï¼Œé¢¨éšªå¯æ§

**æ¨è–¦é€²å…¥**: å¯¦æ–½éšæ®µ

